<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>bartMan • bartMan</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="bartMan">
<meta property="og:description" content="bartMan">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">bartMan</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/bartManVignette.html">bartMan</a>
    </li>
    <li>
      <a href="../articles/bartVisVignette.html">bartMan</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="bartManVignette_files/header-attrs-2.10/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>bartMan</h1>
            
      
      
      <div class="hidden name"><code>bartManVignette.Rmd</code></div>

    </div>

    
    
<!-- avoid border around images -->
<style>
    img {
        border: 0;
    }
</style>
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>Tree-based regression and classification has become a standard tool
in modern data science. Bayesian Additive Regression Trees (BART)<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> has in
particular gained wide popularity due its flexibility in dealing with
interactions and non-linear effects. BART is a Bayesian tree-based
machine learning method that can be applied to both regression and
classification problems and yields competitive or superior results when
compared to other predictive models. As a Bayesian model, BART allows
the practitioner to explore the uncertainty around predictions through
the posterior distribution. In the <code>bartMan</code> package, we
present new visualization techniques for exploring BART models. We
construct conventional plots to analyze a model’s performance and
stability as well as create new tree-based plots to analyze variable
importance, interaction, and tree structure. We employ Value Suppressing
Uncertainty Palettes (VSUP)<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> to construct heatmaps that display variable
importance and interactions jointly using color scale to represent
posterior uncertainty. Our new visualizations are designed to work with
the most popular BART R packages available, namely <code>BART</code><a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>,
<code>dbarts</code><a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>, and <code>bartMachine</code><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>.</p>
<p>In this document, we demonstrate our visualisations for evaluation of
BART models using the <code>bartMan</code> (BART Model ANalysis)
package.</p>
<div id="install-instructions" class="section level2">
<h2 class="hasAnchor">
<a href="#install-instructions" class="anchor"></a>Install instructions</h2>
<p>To install the development version from GitHub, use:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># install.packages("devtools")</span>
<span class="co">#devtools::install_github("AlanInglis/bartMan")</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">bartMan</span><span class="op">)</span></code></pre></div>
<p>The data used in the following examples is simulated from the
Friedman benchmark problem 7<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>. This benchmark problem is commonly used
for testing purposes. The output is created according to the
equation:</p>
<center>
<span class="math display">\[y = 10 sin(π x_1 x_2) + 20 (x_3 - 0.5)^2 +
10 x_4 + 5 x_5 + e\]</span>
</center>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co">## Create some data</span>
<span class="va">f</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span>
  <span class="fl">10</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="va">pi</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span> <span class="fl">20</span> <span class="op">*</span> <span class="op">(</span><span class="va">x</span><span class="op">[</span>, <span class="fl">3</span><span class="op">]</span> <span class="op">-</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">+</span>
    <span class="fl">10</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span>, <span class="fl">4</span><span class="op">]</span> <span class="op">+</span> <span class="fl">5</span> <span class="op">*</span> <span class="va">x</span><span class="op">[</span>, <span class="fl">5</span><span class="op">]</span>
<span class="op">}</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1701</span><span class="op">)</span>
<span class="va">sigma</span> <span class="op">&lt;-</span> <span class="fl">1.0</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">200</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="fl">10</span><span class="op">)</span>, <span class="va">n</span>, <span class="fl">10</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"x"</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span>
<span class="va">Ey</span> <span class="op">&lt;-</span> <span class="fu">f</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, <span class="va">Ey</span>, <span class="va">sigma</span><span class="op">)</span>
<span class="va">fData</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span>

<span class="va">x</span> <span class="op">&lt;-</span> <span class="va">fData</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="va">fData</span><span class="op">$</span><span class="va">y</span></code></pre></div>
<p>Now we will create some basic BART models. To begin we load the
libraries and then create our models.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># load libraries</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">BART</span><span class="op">)</span> <span class="co"># for model</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/vdorie/dbarts">dbarts</a></span><span class="op">)</span> <span class="co"># for model</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">bartMachine</span><span class="op">)</span> <span class="co"># for model</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://patchwork.data-imaginist.com">patchwork</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">gridExtra</span><span class="op">)</span> <span class="co"># for displaying plots</span></code></pre></div>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R">
<span class="co"># create BART model:</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">99</span><span class="op">)</span>
<span class="va">bartModel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BART/man/wbart.html">wbart</a></span><span class="op">(</span>x.train <span class="op">=</span> <span class="va">x</span>,
                   y.train <span class="op">=</span> <span class="va">y</span>,
                   nskip <span class="op">=</span> <span class="fl">100</span>,
                   ndpost <span class="op">=</span> <span class="fl">500</span>,
                   nkeeptreedraws <span class="op">=</span> <span class="fl">500</span>,
                   ntree <span class="op">=</span> <span class="fl">20</span>
                   <span class="op">)</span>

<span class="co"># create dbarts model:</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">99</span><span class="op">)</span>
<span class="va">dbartModel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dbarts/man/bart.html">bart</a></span><span class="op">(</span><span class="va">x</span>,
                   <span class="va">y</span>,
                   ntree <span class="op">=</span> <span class="fl">20</span>,
                   keeptrees <span class="op">=</span> <span class="cn">TRUE</span>,
                   nskip <span class="op">=</span> <span class="fl">10</span>,<span class="co">#100,</span>
                   ndpost <span class="op">=</span> <span class="fl">50</span>,<span class="co">#500</span>
                   <span class="op">)</span>


<span class="co"># create bartMachine model </span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">90</span><span class="op">)</span>
<span class="va">bartMachineModel</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://rdrr.io/pkg/bartMachine/man/bartMachine.html">bartMachine</a></span><span class="op">(</span>X <span class="op">=</span> <span class="va">x</span>,
                   y <span class="op">=</span> <span class="va">y</span>,
                   num_trees <span class="op">=</span> <span class="fl">20</span>,
                   flush_indices_to_save_RAM <span class="op">=</span> <span class="cn">FALSE</span>,
                   num_burn_in <span class="op">=</span> <span class="fl">50</span>,
                   num_iterations_after_burn_in <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></code></pre></div>
<p>The first step in using <code>bartMan</code> is to create a dataframe
of the trees used to build each model. This dataframe is used by many of
the <code>bartMan</code> functions to create the visualizations. We
extract the tree data for each model via:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Create data frames ------------------------------------------------------</span>
<span class="co">#btT &lt;- extractTreeData(model = bartModel,  data = fData) </span>
<span class="va">dbT</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extractTreeData.html">extractTreeData</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">dbartModel</span>, data <span class="op">=</span> <span class="va">fData</span><span class="op">)</span> 
<span class="co">#bmT &lt;- extractTreeData(model= bartMachineModel, data = fData) </span></code></pre></div>
<p>The structure of the data frame of trees created by
<code>extractTreeData</code> is the same, no matter which BART package
is used to build the model. Taking a look at the output from the
<code>dbarts</code> model gives us:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">dbT</span><span class="op">$</span><span class="va">structure</span>
<span class="co">#&gt; # A tibble: 3,778 × 12</span>
<span class="co">#&gt;    var   splitValue  node isLeaf leafValue iteration treeNum label         value</span>
<span class="co">#&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;lgl&gt;      &lt;dbl&gt;     &lt;int&gt;   &lt;int&gt; &lt;chr&gt;         &lt;dbl&gt;</span>
<span class="co">#&gt;  1 x2        0.631      1 FALSE    NA              1       1 x2 ≤ 0.6311  0.631 </span>
<span class="co">#&gt;  2 &lt;NA&gt;     NA          2 TRUE      0.0121         1       1 0.0121       0.0121</span>
<span class="co">#&gt;  3 &lt;NA&gt;     NA          3 TRUE      0.0291         1       1 0.0291       0.0291</span>
<span class="co">#&gt;  4 x2        0.0296     1 FALSE    NA              1       2 x2 ≤ 0.0296  0.0296</span>
<span class="co">#&gt;  5 &lt;NA&gt;     NA          2 TRUE     -0.0512         1       2 -0.0512     -0.0512</span>
<span class="co">#&gt;  6 x2        0.049      3 FALSE    NA              1       2 x2 ≤ 0.049   0.049 </span>
<span class="co">#&gt;  7 &lt;NA&gt;     NA          4 TRUE      0.0211         1       2 0.0211       0.0211</span>
<span class="co">#&gt;  8 &lt;NA&gt;     NA          5 TRUE      0.0363         1       2 0.0363       0.0363</span>
<span class="co">#&gt;  9 x3        0.783      1 FALSE    NA              1       3 x3 ≤ 0.7826  0.783 </span>
<span class="co">#&gt; 10 &lt;NA&gt;     NA          2 TRUE     -0.0613         1       3 -0.0613     -0.0613</span>
<span class="co">#&gt; # … with 3,768 more rows, and 3 more variables: depthMax &lt;dbl&gt;, obsNode &lt;list&gt;,</span>
<span class="co">#&gt; #   noObs &lt;int&gt;</span></code></pre></div>
<p>Here we can see that <code>extractTreeData</code> gives back a
dataframe with 12 columns, which are outlined below.</p>
<p><br></p>
<table class="table">
<table class="table">
<thead><tr class="header">
<th align="left">Column Name</th>
<th align="right">Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">var</td>
<td align="right">The name of the variable used in the splitting
rule.</td>
</tr>
<tr class="even">
<td align="left">splitValue</td>
<td align="right">The split value.</td>
</tr>
<tr class="odd">
<td align="left">node</td>
<td align="right">The number of the node in the tree (following
left-side traversal).</td>
</tr>
<tr class="even">
<td align="left">isLeaf</td>
<td align="right">Is the node a leaf node or not.</td>
</tr>
<tr class="odd">
<td align="left">leafValue</td>
<td align="right">The leaf node value.</td>
</tr>
<tr class="even">
<td align="left">iteration</td>
<td align="right">The iteration number.</td>
</tr>
<tr class="odd">
<td align="left">treeNum</td>
<td align="right">The tree number per iteration.</td>
</tr>
<tr class="even">
<td align="left">label</td>
<td align="right">Displays the split rule in full.</td>
</tr>
<tr class="odd">
<td align="left">value</td>
<td align="right">The value in a node (i.e., either the split value or
leaf value).</td>
</tr>
<tr class="even">
<td align="left">depthMax</td>
<td align="right">The maximum depth of the tree.</td>
</tr>
<tr class="odd">
<td align="left">obsNode</td>
<td align="right">A list containing the observations contained in each
node.</td>
</tr>
<tr class="even">
<td align="left">noObs</td>
<td align="right">The number of observations in a particular node.</td>
</tr>
</tbody>
</table>
<center>
<caption>
<span id="tab:table2">Table 1: </span>Data frame of tree structures.
</caption>
</center>
</table>
<p>In all of the following visualizations we use the <code>dbarts</code>
model fit (unless otherwise stated). However, the process is identical
for any of the aforementioned BART packages.</p>
</div>
<div id="vivi-vsup" class="section level2">
<h2 class="hasAnchor">
<a href="#vivi-vsup" class="anchor"></a>VIVI-VSUP</h2>
<p>In Inglis et al. (2022)<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>, the authors propose using a heatmap to
display both importance and interactions simultaneously, where the
importance values are on the diagonal and interaction values on the
off-diagonal. We adapt the heatmap displays of importance and
interactions to include the uncertainty by use of a VSUP. To begin we
fist generate a list of two matrices. One containing the raw inclusion
proportions and one containing the uncertainties. Here we use the
coefficient of variation as our uncertainty measure. However the
standard deviation or standard error is also available by setting
<code>metricError = 'SD'</code>and <code>metricError = 'SE'</code>, in
the code below respectivley.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">vsupMat</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/viviBartMatrix.html">viviBartMatrix</a></span><span class="op">(</span><span class="va">dbT</span>,
                          type <span class="op">=</span> <span class="st">'vsup'</span>,
                          metric <span class="op">=</span> <span class="st">'propMean'</span>,
                          metricError <span class="op">=</span> <span class="st">"CV"</span><span class="op">)</span></code></pre></div>
<p>Once the matrices have been created, they can be plotted displaying a
VSUP plot with the uncertainty included. For illustration purposes only
we show the plot without uncertainty in Figure 1 and with uncertainty in
Figure 2:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># set up colors to match the vsup</span>

<span class="va">colors</span> <span class="op">&lt;-</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/colour_ramp.html">colour_ramp</a></span><span class="op">(</span>
  colors <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>blue <span class="op">=</span> <span class="st">'#FFFFCC'</span>, red <span class="op">=</span> <span class="st">'#800026'</span><span class="op">)</span>
<span class="op">)</span><span class="op">(</span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">7</span><span class="op">)</span><span class="op">/</span><span class="fl">7</span><span class="op">)</span>

<span class="va">newCols</span> <span class="op">&lt;-</span> <span class="fu">RColorBrewer</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/RColorBrewer/man/ColorBrewer.html">brewer.pal</a></span><span class="op">(</span><span class="fl">9</span>, <span class="st">'GnBu'</span><span class="op">)</span>
<span class="va">colors2</span> <span class="op">&lt;-</span> <span class="va">newCols</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span>


<span class="fu">vivid</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/vivid/man/viviHeatmap.html">viviHeatmap</a></span><span class="op">(</span><span class="va">vsupMat</span><span class="op">$</span><span class="va">actualMatrix</span>,
                   intPal <span class="op">=</span> <span class="va">colors</span>,
                   impPal <span class="op">=</span> <span class="va">colors2</span><span class="op">)</span> </code></pre></div>
<img src="../../../vigplots/vivi.png" width="386"><caption>
<span id="fig1:fig1">Figure 1: </span> Variable importance and
interaction plot without uncertainty. The five important variables
(<span class="math inline">\(x_1\)</span> to <span class="math inline">\(x_5\)</span>) and the interaction between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> is clear.
</caption>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/viviBartPlot.html">viviBartPlot</a></span><span class="op">(</span><span class="va">vsupMat</span>,
             max_desat <span class="op">=</span> <span class="fl">1</span>,
             pow_desat <span class="op">=</span> <span class="fl">0.6</span>,
             max_light <span class="op">=</span> <span class="fl">0.6</span>,
             pow_light <span class="op">=</span> <span class="fl">1</span>,
             label <span class="op">=</span> <span class="st">'CV'</span><span class="op">)</span></code></pre></div>
<p><img src="../../../vigplots/vsup.png" width="386"></p>
<caption>
<span id="fig2:fig2">Figure 2: </span> Variable importance and
interaction plot with uncertainty. We can see that the interaction
values for the noise variables have a high coefficient of variation
associated with them..
</caption>
</div>
<div id="tree-based-plots" class="section level2">
<h2 class="hasAnchor">
<a href="#tree-based-plots" class="anchor"></a>Tree Based Plots</h2>
<p>Here examine more closely the structure of the decision trees created
when building a BART model. Examining the tree structure may yield
information on the stability and variability of the tree structures as
the algorithm iterates to create the posterior. By sorting and coloring
the trees appropriately we can identify important variables and common
interactions between variables for a given iteration. Alternatively we
can look at how a single tree evolves through the iteration to explore
the fitting algorithm’s stability.</p>
<p>To plot an individual tree, we can choose to display it either in
dendrogram format, or icicle format. Additionally, we can choose which
tree number or iteration to display:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/plotTree.html">plotTree</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, treeNo <span class="op">=</span> <span class="fl">1</span>, iter <span class="op">=</span> <span class="fl">1</span>, plotType <span class="op">=</span> <span class="st">"dendrogram"</span><span class="op">)</span> 
<span class="fu"><a href="../reference/plotTree.html">plotTree</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, treeNo <span class="op">=</span> <span class="fl">1</span>, iter <span class="op">=</span> <span class="fl">1</span>, plotType <span class="op">=</span> <span class="st">"icicle"</span><span class="op">)</span></code></pre></div>
<img src="../../../vigplots/dendice.png" width="100%"><caption>
<span id="fig3:fig3">Figure 3: </span>A dendrogram plot of a selected
tree (left) and an icicle plot of a selected tree (right). In the icicle
plot, the nodes are coloured by the variable used in the splitting rule.
Leaf (terminal) nodes are coloured grey.
</caption>
<p>The <code>plotAllTrees</code> function allows for a few different
options when plotting. For example, we can chose to display all the
trees from a selected iteration:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/plotAllTrees.html">plotAllTrees</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, iter <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
<img src="../../../vigplots/allTrees.png" width="100%"><caption>
<span id="fig4:fig4">Figure 4: </span>All trees from a single iteration.
In this case the first iteration is shown.
</caption>
<p>Additionally, we can plot a single tree over all iterations. This
shows us visually BART’s <em>grow, prune, change, swap</em> mechanisms
in action:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/plotAllTrees.html">plotAllTrees</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, treeNo <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></code></pre></div>
<img src="../../../vigplots/treeNo.png" width="100%"><caption>
<span id="fig5:fig5">Figure 5: </span>A single tree over all iterations.
</caption>
<p>When viewing the trees, it can be useful to view different aspects or
metrics.</p>
<p>In Figure 6 we show some of these aspects by displaying all the trees
in a selected iteration. For example, in (a) we color terminal nodes and
stumps by the mean response. In (b) we color them by the terminal node
parameter value. In (c) we sort the trees by structure starting with the
most common tree and descending to the least common tree found (useful
for identifying the most important splits). Finally, in (d) we sort the
trees by depth. As the <span class="math inline">\(\mu\)</span> values
in (b) are centered around zero, we use a single-hue, colorblind
friendly, diverging color palette to display the values. For comparison,
we use the same palette to represent the mean response values in
(a).</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/plotAllTrees.html">plotAllTrees</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, iter <span class="op">=</span> <span class="fl">1</span>, sizeNode <span class="op">=</span> <span class="cn">T</span>, fillBy <span class="op">=</span> <span class="st">'mu'</span>, pal <span class="op">=</span> <span class="va">mypalette</span><span class="op">)</span>
<span class="fu"><a href="../reference/plotAllTrees.html">plotAllTrees</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, iter <span class="op">=</span> <span class="fl">1</span>, sizeNode <span class="op">=</span> <span class="cn">T</span>, fillBy <span class="op">=</span> <span class="st">'response'</span>, pal <span class="op">=</span> <span class="va">mypalette</span><span class="op">)</span>
<span class="fu"><a href="../reference/plotAllTrees.html">plotAllTrees</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, iter <span class="op">=</span> <span class="fl">1</span>, cluster <span class="op">=</span> <span class="st">"depth"</span><span class="op">)</span>
<span class="fu"><a href="../reference/plotAllTrees.html">plotAllTrees</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, iter <span class="op">=</span> <span class="fl">1</span>, cluster <span class="op">=</span> <span class="st">"var"</span><span class="op">)</span></code></pre></div>
<img src="../../../vigplots/treesmet.png" width="100%"><caption>
<span id="fig6:fig6">Figure 6: </span>All trees in a selected iteration.
In (a) the terminal nodes and stumps are colored by the mean response.
In (b) the terminal nodes and stumps are colored by the predicted value
<span class="math inline">\(\mu\)</span>. In (c) we sort the trees by
structure starting with the most common tree and descending to the least
common tree shape and in (d) we sort the trees by tree depth.
</caption>
<p>As an alternative to the sorting of the tree structures, seen in
Figure 6 (c), we provide a bar plot summarizing the tree structures.
Here we choose to display the top 10 most frequent tree structures,
however displaying a single tree across iterations or displaying all
trees in a single iteration is possible via the <code>iter</code> and
<code>treeNo</code> arguments.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/treeBarPlot.html">treeBarPlot</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, topTrees <span class="op">=</span> <span class="fl">10</span>, iter <span class="op">=</span> <span class="cn">NULL</span>, treeNo <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span></code></pre></div>
<p><img src="../../../vigplots/barplot.png" width="80%"></p>
<caption>
<span id="fig6:fig6">Figure 6: </span> Bar plot of the top 10 most
frequent tree types over all iterations. Trees with a single binary
split on Petal.Length occur the most often.
</caption>
</div>
<div id="proximity-matrix-and-multidimensional-scaling" class="section level2">
<h2 class="hasAnchor">
<a href="#proximity-matrix-and-multidimensional-scaling" class="anchor"></a>Proximity Matrix and Multidimensional Scaling</h2>
<p>Proximity matrices combined with multidimensional scaling (MDS) are
commonly used in random forests to identify outlying observations<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>. When two
observations lie in the same terminal node repeatedly they can be said
to be similar, and so an <span class="math inline">\(N × N\)</span>
proximity matrix is obtained by accumulating the number of times at
which this occurs for each pair of observations, and subsequently
divided by the total number of trees. A higher value indicates that two
observations are more similar.</p>
<p>To begin, we fist create a proximity matrix. This can be seriated to
group similar observations together by setting
<code>reorder = TRUE</code>. The <code>normailze</code> argument will
divide the proximity scores by the total number of trees. Additionally,
we can choose to get the proximity matrix for a single iteration (as
shown below) or over all iterations 9the latter is achieved by setting
<code>iter = NUll</code>.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">bmProx</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/proximityMatrix.html">proximityMatrix</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>,
                          data <span class="op">=</span> <span class="va">fData</span>, 
                          reorder <span class="op">=</span> <span class="cn">TRUE</span>, 
                          normalize <span class="op">=</span> <span class="cn">TRUE</span>, 
                          iter <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
<p>We can then visualise the proximity matrix using the
<code>plotProximity</code> function. in the interest of space, we only
display the first 50 rows and columns of the porximty matrix.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/plotProximity.html">plotProximity</a></span><span class="op">(</span>matrix <span class="op">=</span> <span class="va">bmProx</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">50</span>,<span class="fl">1</span><span class="op">:</span><span class="fl">50</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu">theme</span><span class="op">(</span>axis.text.x <span class="op">=</span> <span class="fu">element_text</span><span class="op">(</span>angle <span class="op">=</span> <span class="fl">90</span>,<span class="op">)</span><span class="op">)</span> </code></pre></div>
<p><img src="../../../vigplots/prox.png" width="80%"></p>
<caption>
<span id="fig7:fig7">Figure 7: </span>Proximity matrix displaying only
the first 50 rows and columns.
</caption>
<p>The proximity matrix can then be visualized using classical MDS
(henceforth MDS) to plot their relationship in a lower dimensional
projection.</p>
<p>In BART, as there is a proximity matrix for every iteration and a
posterior distribution of proximity matrices. We introduce a rotational
constraint so that we can similarly obtain a posterior distribution of
each observation in the lower dimensional space. We first choose a
target iteration (as shown above) and apply MDS. For each subsequent
iteration we rotate the MDS solution matrix to match this target as
closely as possible using Procrustes’ method. We end up with a point for
each observation per iteration per MDS dimension.We then group the
observations by the mean of each group and produce a scatterplot, where
each point represents the centroid of the location of each observation
across all the MDS solutions. We extend this further by displaying the
95% confidence ellipses around each observation’s posterior location in
the reduced space. Since these are often overlapping we have created an
interactive version that highlights an observation’s ellipse and
displays the observation number when hovering the mouse pointer above
the ellipse (Figure 8 shows a screenshot of this interaction in use).
However, non-interactive versions are available via the
<code>plotType</code> argument.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/mdsBart.html">mdsBart</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, data <span class="op">=</span> <span class="va">fData</span>, target <span class="op">=</span>  <span class="va">bmProx</span>,
        plotType <span class="op">=</span> <span class="st">'interactive'</span><span class="op">)</span></code></pre></div>
<p><img src="../../../vigplots/mds.png" width="80%"></p>
<caption>
<span id="fig8:fig8">Figure 8: </span>Interactive MDS plot. Each 95%
confidence ellipse corresponds to each observation’s posterior location.
When hovering the mouse pointer over an ellipse, the ellipse is
highlighted and the observation is displayed.
</caption>
</div>
<div id="enhanced-bart-model-diagnostics" class="section level2">
<h2 class="hasAnchor">
<a href="#enhanced-bart-model-diagnostics" class="anchor"></a>Enhanced BART model diagnostics</h2>
<p>In addition to the above, we also provide visualisations for general
diagnostics of a BART model. These include checking for convergence, the
stability of the trees, the efficiency of the algorithm, and the
predictive performance of the model. To begin we take a look at some
general diagnostics to assess the stability of the model fit. the
<code>burnIn</code> argument should be set to the burn-in value selected
when building the model and indicates the separation between the pre and
post burn-in period in the plot.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/bartDiag.html">bartDiag</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">dbartModel</span>, response <span class="op">=</span> <span class="va">fData</span><span class="op">$</span><span class="va">y</span>, burnIn <span class="op">=</span> <span class="fl">10</span>, data <span class="op">=</span> <span class="va">fData</span><span class="op">)</span></code></pre></div>
<p><img src="../../../vigplots/diag.png" width="80%"></p>
<caption>
<span id="fig9:fig9">Figure 9: </span>General diagnostic plots for a
BART regression fit. Top left: A QQ-plot of the residuals after fitting
the model. Top right: <span class="math inline">\(\sigma\)</span> by
MCMC iteration. Middle left: Residuals versus fitted values with 95%
credible intervals. Middle right: A histogram of the residuals. Bottom
Left: Actual values versus fitted values with 95% credible intervals.
Bottom right: Variable importance plot with 25 to 75% quantile interval
shown.
</caption>
<p>The post burn-in percentage acceptance rate across all iterations can
also be visualized, where each point represents a single iteration. A
regression line is shown to indicate the changes in acceptance rate
across iterations and to identify the mean rate.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/acceptRate.html">acceptRate</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span><span class="op">)</span></code></pre></div>
<p><img src="../../../vigplots/accept.png" width="50%" style="display: block; margin: auto;"></p>
<caption>
<span id="fig10:fig10">Figure 10: </span> Post burn-in acceptance rate
of trees per iteration. A black regression line is shown to indicate the
changes in acceptance rate across iterations and to identify the mean
rate.
</caption>
<p>As with the acceptance rate, the average tree depth and average
number of all nodes per iteration can give an insight into the fit’s
stability. Figure 11 displays these two metrics. A locally estimated
scatterplot smoothing (LOESS) regression line is shown to indicate the
changes in both the average tree depth and the average number of nodes
across iterations:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/treeDepth.html">treeDepth</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span><span class="op">)</span>
<span class="fu"><a href="../reference/treeNodes.html">treeNodes</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span><span class="op">)</span></code></pre></div>
<p><img src="../../../vigplots/treeDepthNode.png" width="100%"></p>
<caption>
<span id="fig11:fig11">Figure 11: </span> In (a) we show the post
burn-in average tree depth per iteration. In (b) we show the post
burn-in average number of nodes per iteration. A black LOESS regression
curve is shown to indicate the changes in both the average tree depth
and number of nodes across iterations.
</caption>
<p>Figure 12 shows the densities of split values over all post burn-in
iterations for each variable for both models (in green), combined with
the densities of the predictor variables (labeled “data”, in red):</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/splitDensity.html">splitDensity</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, data <span class="op">=</span> <span class="va">fData</span>, display <span class="op">=</span> <span class="st">'both2'</span><span class="op">)</span></code></pre></div>
<p><img src="../../../vigplots/splitDens.png" width="100%"></p>
<caption>
<span id="fig12:fig12">Figure 12: </span> Split values densities (in
green) over all iterations for each variable overlayed on the densities
of the predictors (in red).
</caption>
</div>
<div id="additional-importance-and-interaction-plots-" class="section level2">
<h2 class="hasAnchor">
<a href="#additional-importance-and-interaction-plots-" class="anchor"></a>Additional Importance and Interaction plots.</h2>
<p>The asses the inclusion proportions for use with variable importance
or variable interactions. We also provide some useful functions for
extracting these values and for visualizing them. For example, to
retrieve a matrix of the inclusion proportions for each variable we can
use the <code>vimpBart</code> function and then to visualize them (with
their 25% to 75% quantile interval included) we use the
<code>vimpPlot</code> function.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># te extract a matrix of inclusion proportions for each variable:</span>
<span class="fu"><a href="../reference/vimpBart.html">vimpBart</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span><span class="op">)</span>

<span class="co"># plot inclusion proportions of each variable:</span>
<span class="fu"><a href="../reference/vimpPlot.html">vimpPlot</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, plotType <span class="op">=</span> <span class="st">'pointGrad'</span><span class="op">)</span></code></pre></div>
<p><img src="../../../vigplots/vimp1.png" width="100%"></p>
<caption>
<span id="fig13:fig13">Figure 13: </span> Inclusion proportions for each
variable shown with the 25% to 75% quantile interval extending from the
points.
</caption>
<p>Similarly, we provide a function for extracting and viewing the
inclusion proportions for interactions (this time displayed as a
barplot, again with 25% to 75% quantile interval included):</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># te extract a dataframe of inclusion proportions for each variable pair:</span>
<span class="fu"><a href="../reference/vintBart.html">vintBart</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span><span class="op">)</span>

<span class="co"># plot inclusion proportions of each variable pair:</span>
<span class="fu">vintPlot</span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, plotType <span class="op">=</span> <span class="st">'barplot'</span><span class="op">)</span></code></pre></div>
<p><img src="../../../vigplots/vint1.png" width="100%"></p>
<caption>
<span id="fig14:fig14">Figure 14: </span> Inclusion proportions for each
variable pair shown with the 25% to 75% quantile interval extending from
the bars
</caption>
<p>Our Final method to display the inclusion proprotions is by using a
<em>Letter-value plot</em><a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>. This type of plot is useful for
visualizing the distribution of a continuous variable (here variable
inclusion proportions), with the inner-most box showing the lower and
upper fourths, as with a conventional boxplot, the median value being
shown as a black line and outliers as blue triangles. Each extending
section is drawn at incremental steps of upper and lower eights,
sixteenths and so on until a stopping rule has been reached. The color
of each box corresponds to the density of the data with darker shades
indicating higher data density.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/vimpPlot.html">vimpPlot</a></span><span class="op">(</span>treeData <span class="op">=</span> <span class="va">dbT</span>, plotType <span class="op">=</span> <span class="st">'lvp'</span><span class="op">)</span> <span class="op">+</span> <span class="fu">coord_flip</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<p><img src="../../../vigplots/lvp.png" width="100%"></p>
<caption>
<span id="fig15:fig15">Figure 15: </span> Letter-value plot of the
Inclusion proportions for each variable.
</caption>
</div>
<div id="null-model-inclusion-proprtions" class="section level2">
<h2 class="hasAnchor">
<a href="#null-model-inclusion-proprtions" class="anchor"></a>Null model inclusion proprtions</h2>
<p>In our package we also implement one of the variable selection
procedures developed in Bleich et al. (2014)<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>, specifically, the
so-called <em>local threshold procedure</em>. In this method, the
proportion of splitting rules is calculated, then the response variable
is randomly permuted, which has the effect of breaking the relationship
between the response and the covariates. The model is then re-built as a
<em>null</em> model using the permuted response. From this, the null
proportion, is calculated and a new measure of importance is
obtained.</p>
<p>When using this method, there are three key arguments. They are;
<code>numRep</code>, <code>numTreesRep</code>, and <code>alpha</code>.
<code>numRep</code> determines the number of replicates to perform for
the BART null model’s variable inclusion proportions. Whereas
<code>numTreesRep</code>, determines the number of trees to be used in
the replicates. <code>alpha</code> sets the cut-off level for the
thresholds. that is, a predictor is deemed important if its variable
inclusion proportion exceeds the 1 − <span class="math inline">\(\alphs\)</span> quantile of its own null
distribution. If setting <code>shift = TRUE</code>, the inclusion
proportions are shifted by the difference in distance between the
quantile and the value of the inclusion proportion point.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/localProcedure.html">localProcedure</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">dbartModel</span>, 
               data <span class="op">=</span> <span class="va">fData</span>, 
               numRep <span class="op">=</span> <span class="fl">5</span>,
               numTreesRep <span class="op">=</span> <span class="fl">5</span>, 
               alpha <span class="op">=</span> <span class="fl">0.5</span>,
               shift <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<p><img src="../../../vigplots/local.png" width="100%"></p>
<caption>
<span id="fig16:fig16">Figure 16: </span> Visualization of the local
procedure variable selection method. The blue lines are the threshold
levels determined from the permutation distributions that must be
exceeded for a variable to be deemed important. The points are the
variable inclusion proportions for the observed data (averaged over a
selected number of duplicate BART models). If the observed value is
higher than the bar, the variable is deemed important and is displayed
as a solid dot; if not, it is displayed as an X.
</caption>
</div>
<div id="combining-categorical-variables" class="section level2">
<h2 class="hasAnchor">
<a href="#combining-categorical-variables" class="anchor"></a>Combining Categorical Variables</h2>
<p>xxxxxxx</p>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr>
<ol>
<li id="fn1"><p>Chipman, H. A., George, E. I., &amp; McCulloch, R. E.
(2010). BART: Bayesian additive regression trees. <em>The Annals of
Applied Statistics</em>, 4(1), 266-298.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Correll, M., Moritz, D., &amp; Heer, J. (2018, April).
Value-suppressing uncertainty palettes. In Proceedings of the 2018 CHI
Conference on Human Factors in Computing Systems (pp. 1-11).<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Sparapani R, Spanbauer C, McCulloch R (2021).
Nonparametric Machine Learning and Efficient Computation with Bayesian
Additive Regression Trees: The BART R Package. <em>Journal of
Statistical Software</em><a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Vincent Dorie, dbarts: Discrete Bayesian Additive
Regression Trees Sampler, 2020<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Adam Kapelner, Justin Bleich (2016). bartMachine:
Machine Learning with Bayesian Additive Regression Trees. <em>Journal of
Statistical Software</em><a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Friedman, Jerome H. (1991) Multivariate adaptive
regression splines. <em>The Annals of Statistics</em> 19 (1), pages
1-67.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Inglis, A., Parnell, A., &amp; Hurley, C. B. (2022).
Visualizing Variable Importance and Variable Interaction Effects in
Machine Learning Models. Journal of Computational and Graphical
Statistics, 1-13.<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Breiman, L. (2001). Random forests. Machine learning,
45(1), 5-32.Chicago<a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>Hofmann, H., Wickham, H., &amp; Kafadar, K. (2017).
value plots: Boxplots for large data. Journal of Computational and
Graphical Statistics, 26(3), 469-477.<a href="#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>Bleich, J., Kapelner, A., George, E. I., &amp; Jensen,
S. T. (2014). Variable selection for BART: an application to gene
regulation. The Annals of Applied Statistics, 8(3), 1750-1781.<a href="#fnref10" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by .</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
