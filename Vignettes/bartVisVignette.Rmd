---
title: "bartMan"
author: "Alan Inglis"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
fig_width: 8 
fig_height: 8 
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
options(rmarkdown.html_vignette.check_title = FALSE)
```


# Introduction
Bayesian Additive Regression Trees (BART) 1^[Chipman et al (2010)] is a non-parametric sum-of-trees-based ensemble method that has gained popularity in recent years due to its competitive performance against other tree-based predictive models, such as Random Forest 2^[Breiman, 2001] or Gradient Boosting Trees 3^[Friedman, 2001]. In BART  an  MCMC  (Markov  Chain  Monte  Carlo)  backfitting  algorithm  is  used  to  accept or reject proposed trees along the iterations, where the structure of the trees is controlled via a prior distribution.  BART can be used for making predictions for both binary and continuous response variables and can be modelled using the R packages dbarts 4^[Vincent Dorie, dbarts: Discrete Bayesian Additive Regression Trees Sampler, 2020], bartMachine 5^[Kapelner and Bleich, {bartMachine}: Machine Learning with {B}ayesian Additive Regression Trees, 2016], and BART 6^[McCulloch et al, Nonparametric Machine Learning and Efficient Computation with {B}ayesian Additive Regression Trees: The {BART} {R} Package, 2019]. 

In this document, we illustrate some visualisations for posterior evaluation of BART models using the bartMan (BART Model ANalysis) package.

## Install instructions
to install the development version from GitHub, use:

```{r setup, warning=FALSE, message=FALSE}
# install.packages("devtools")
#devtools::install_github("AlanInglis/vivid")
library(bartMan)
```


The data used in the following examples is simulated from the Friedman benchmark problem 7^[Friedman, Jerome H. (1991) Multivariate adaptive regression splines. The Annals of Statistics 19 (1), pages 1-67.]. This benchmark problem is commonly used for testing purposes. The output is created according to the equation:

<center>
$$y = 10 sin(Ï€ x_1 x_2) + 20 (x_3 - 0.5)^2 + 10 x_4 + 5 x_5 + e$$
```{r}
## Create some data
f <- function(x) {
  10 * sin(pi * x[, 1] * x[, 2]) + 20 * (x[, 3] - 0.5)^2 +
    10 * x[, 4] + 5 * x[, 5]
}

set.seed(1701)
sigma <- 1.0
n <- 200
x <- matrix(runif(n * 10), n, 10)
colnames(x) <- paste0("x", 1:10)
Ey <- f(x)
y <- rnorm(n, Ey, sigma)
fData <- as.data.frame(cbind(x, y))

x <- fData[, 1:10]
y <- fData$y

```

Now we will create some basic BART models. To begin we load the libraries and then create our models.

```{r, results =  'hide'}
# load libraries
library(BART)
library(dbarts)
library(bartMachine)
library(gridExtra) # for plots

# create BART model:
set.seed(99)
bartModel <- wbart(x.train = x,
                   y.train = y,
                   nskip = 50,
                   ndpost = 200,
                   nkeeptreedraws = 200,
                   ntree = 20
                   )

# create dbarts model:
set.seed(99)
dbartModel <- bart(x,
                   y,
                   ntree = 20,
                   keeptrees = TRUE,
                   nskip = 100,
                   ndpost = 500
                   )


# create bartMachine model (smaller to save time)
set.seed(90)
bartMachineModel <-  bartMachine(X = x,
                   y = y,
                   num_trees = 20,
                   flush_indices_to_save_RAM = FALSE,
                   num_burn_in = 50,
                   num_iterations_after_burn_in = 100)

```


Now we create a list of tree attributes, containing the tree structure for all the trees and additional information of the model. We extract the tree data for each model.

```{r}
# Create data frames ------------------------------------------------------
btT <- extractTreeData(bartModel, data = fData) 
dbT <- extractTreeData(dbartModel) 
bmT <- extractTreeData(bartMachineModel) 
```


Taking a look at at the structure for the BART model:
```{r}
btT
```


* Diagnostic Plots

To view the acceptance rate of the trees, we use the `acceptanceRate` function. This function has an additional argument to select the burn-in.
```{r}
# acceptance rate
acceptRate(treeData = btT, burnIn = 100) # BART
```

Additionally, we can also view the tree depth per iteration and the average number of nodes per iteration:
```{r}
# tree depth per iteration
td <- treeDepth(treeData = btT, burnIn = 100) # BART
# tree nodes per iteration
tn <- treeNodes(treeData = btT, burnIn = 100)

grid.arrange(td, tn, ncol=2)
```


The `splitDensity` function shows the frequency of split values:
```{r}
splitDensity(btT)
```


To create a proximity matrix, we first run the `proximityMatrix` function. This function has a `nRows` argument which considers only the rows selected from the data. For illustration purposes, rows 1-25 are selected. After the proximity matrix has been created, it can be plotted using the `plotProximity` function:
```{r}
pM <- proximityMatrix(treeData = btT, data = fData, nRows = c(1:25), reorder = T, 
                      normalize = T)
plotProximity(pM)
```

Finally, for a more complete diagnostic, we can use:

```{r}
bartDiag(model = bartModel, response = y, burnIn = 100)
```

## VIVI

To view the variable importance and variable interaction (with uncertainty included) we use the `viviBart` function. This creates a collection of matrices with importance on the diagonal and interaction on the off-diagonal. The `noReplications` argument repeats the running of the function a selected amount of times. For speed purposes, it is set to 2 here. Once the matrices have been created, they can be plotted displaying a VSUP[REFERENCE] plot with the uncertainty included:
```{r, results =  'hide'}
bMatrix <- viviBart(model = bartModel,
                   response = "y",
                   data = fData,
                   noReplications = 2,
                   gridSize = 10,
                   nmax = 30,
                   normalized = T,
                   reorder = T
)
```

```{r}
viviBartPlot(bMatrix)
```
## Tree Based Plots

To plot an individual tree, we can choose to display it either in dendrogram format, or icicle format. Additionally, we can choose which tree number or iteration to display:
```{r}
dend <- plotTree(btT, treeNo = 1, iter = 1, plotType = "dendrogram")
ice  <- plotTree(btT, treeNo = 1, iter = 1, plotType = "icicle")

grid.arrange(dend, ice, ncol=2)
```

The `plotAllTrees` allows for a few different options when plotting. To begin, if no iteration or tree number is defined, we automatically plot all the trees from the final iteration:
```{r}
plotAllTrees(btT) # final iteration
```

We can also choose which tree number to display. For example, if we pick tree number 1, we display that tree over all iterations:
```{r}
plotAllTrees(btT, treeNo = 1)
```

Additionally, we can cluster the displayed trees by either the variable. The plot below show the final iteration, clustered by the variable.
```{r}
plotAllTrees(btT, cluster = "var")
```

Or we can cluster by the depth of the trees. The plot below show the final iteration, clustered by the depth of the trees
```{r}
plotAllTrees(btT, cluster = "depth")
```


A useful summary for looking at the frequency of trees is to use the `treeBarPlot` function:
```{r}
treeBarPlot(btT, topTrees = 5)
```
